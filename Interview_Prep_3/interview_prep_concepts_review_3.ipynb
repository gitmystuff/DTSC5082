{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC5082/blob/main/Interview_Prep_3/interview_prep_concepts_review_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxVUwAOxA7gD"
      },
      "source": [
        "# Statistical Foundations to Hypothesis Testing\n",
        "\n",
        "## A Hands-On Journey Through Probability and Inference\n",
        "\n",
        "Welcome! In this notebook, you'll build a complete understanding of hypothesis testing by exploring the foundational concepts that make it possible. We'll start with basic probability concepts and progressively build toward making statistical inferences about populations.\n",
        "\n",
        "### The Big Picture\n",
        "\n",
        "Imagine you're a data scientist who needs to answer questions like:\n",
        "- \"Is this new drug more effective than the placebo?\"\n",
        "- \"Did our website redesign increase user engagement?\"\n",
        "- \"Is there a real difference in test scores between two teaching methods?\"\n",
        "\n",
        "To answer these questions scientifically, we need **hypothesis testing**. But hypothesis testing relies on a deep understanding of probability, distributions, and statistical inference. That's exactly what we'll build today.\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "1. How to quantify uncertainty with **Expected Value**\n",
        "2. How **Binomial Distribution** models repeated experiments\n",
        "3. How the Binomial becomes the **Normal Distribution** with enough trials\n",
        "4. How to estimate parameters using **Least Squares** and **Maximum Likelihood**\n",
        "5. How to think about **Conditional Probability**\n",
        "6. How to work with distribution functions: **PDF, CDF, PPF, PMF, and KDE**\n",
        "7. How the **Law of Large Numbers** and **Central Limit Theorem** enable inference\n",
        "8. How to conduct **Hypothesis Tests** with confidence\n",
        "\n",
        "### How This Notebook Works\n",
        "\n",
        "- ðŸ“– **Read** the explanations carefully\n",
        "- âœï¸ **Complete** the code cells (look for `# YOUR CODE HERE` or `___`)\n",
        "- ðŸŽ¨ **Visualize** the concepts through graphs\n",
        "- ðŸ¤” **Think** about the questions posed\n",
        "- ðŸƒ **Run** each cell in order (Shift+Enter)\n",
        "\n",
        "Let's begin!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfEXsOizA7gE"
      },
      "source": [
        "---\n",
        "## Setup: Import Libraries\n",
        "\n",
        "First, let's import the tools we'll need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euG-OTREA7gF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import binom, norm, gaussian_kde\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set style for better-looking plots\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "print(\"âœ“ Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34vtMxxpA7gF"
      },
      "source": [
        "---\n",
        "## Part 1: Expected Value - The Foundation of Decision Making\n",
        "\n",
        "### What is Expected Value?\n",
        "\n",
        "**Expected Value** (E[X] or Î¼) is the long-run average outcome if you repeat an experiment infinitely many times. It's the center of gravity of a probability distribution.\n",
        "\n",
        "**Formula**: E[X] = Î£(x Ã— P(x)) for all possible values x\n",
        "\n",
        "### Example: A Simple Game\n",
        "\n",
        "You roll a fair six-sided die:\n",
        "- If you roll 6, you win $10\n",
        "- If you roll 1-5, you win $0\n",
        "\n",
        "Should you play if it costs $2 to play?\n",
        "\n",
        "Let's calculate!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo1FXxgcA7gF"
      },
      "outputs": [],
      "source": [
        "# Calculate expected value of the die game\n",
        "outcomes = [0, 0, 0, 0, 0, 10]  # outcomes for rolling 1,2,3,4,5,6\n",
        "probabilities = [1/6, 1/6, 1/6, 1/6, 1/6, 1/6]\n",
        "\n",
        "# Expected value formula: sum of (outcome * probability)\n",
        "expected_value = sum([outcome * prob for outcome, prob in zip(outcomes, probabilities)])\n",
        "\n",
        "print(f\"Expected winnings per game: ${expected_value:.2f}\")\n",
        "print(f\"Cost to play: $2.00\")\n",
        "print(f\"Expected profit: ${expected_value - 2:.2f}\")\n",
        "print(f\"\\nShould you play? {'Yes!' if expected_value > 2 else 'No!'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkvg54pPA7gF"
      },
      "source": [
        "### ðŸŽ¯ Your Turn: Calculate Expected Value\n",
        "\n",
        "A lottery ticket costs $5. The prizes are:\n",
        "- Win $100 with probability 0.01 (1%)\n",
        "- Win $20 with probability 0.05 (5%)\n",
        "- Win $0 with probability 0.94 (94%)\n",
        "\n",
        "Is this lottery worth playing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXTFVrRKA7gG"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE: Calculate the expected value\n",
        "lottery_outcomes = [100, 20, 0]\n",
        "lottery_probs = [___, ___, ___]  # Fill in the probabilities\n",
        "\n",
        "lottery_ev = sum([outcome * prob for outcome, prob in zip(lottery_outcomes, lottery_probs)])\n",
        "\n",
        "print(f\"Expected winnings: ${lottery_ev:.2f}\")\n",
        "print(f\"Expected profit (after $5 ticket): ${lottery_ev - 5:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsaU0Nm4A7gG"
      },
      "source": [
        "### Why Expected Value Matters for Hypothesis Testing\n",
        "\n",
        "Expected value is crucial because:\n",
        "1. It defines the **center** of a distribution (the mean)\n",
        "2. We use it to calculate **test statistics**\n",
        "3. It helps us understand what we **expect** to see under the null hypothesis\n",
        "\n",
        "When we test hypotheses, we're essentially asking: \"Is what we observed far enough from what we expected?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnHQ2LmYA7gG"
      },
      "source": [
        "---\n",
        "## Part 2: The Binomial Distribution - Counting Successes\n",
        "\n",
        "### What is the Binomial Distribution?\n",
        "\n",
        "The **Binomial Distribution** models the number of successes in a fixed number of independent trials, where each trial has:\n",
        "- Two possible outcomes (success/failure)\n",
        "- The same probability of success (p)\n",
        "\n",
        "**Parameters**:\n",
        "- n = number of trials\n",
        "- p = probability of success on each trial\n",
        "\n",
        "**Examples**:\n",
        "- Number of heads in 10 coin flips\n",
        "- Number of patients cured out of 100 treated\n",
        "- Number of defective items in a batch of 50\n",
        "\n",
        "### Example: Coin Flipping\n",
        "\n",
        "Let's flip a fair coin 10 times and count the heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpLrXmwVA7gG"
      },
      "outputs": [],
      "source": [
        "# Simulate flipping a fair coin 10 times\n",
        "n_flips = 10\n",
        "p_heads = 0.5\n",
        "\n",
        "# Simulate many sets of 10 flips\n",
        "n_simulations = 10000\n",
        "results = []\n",
        "\n",
        "for _ in range(n_simulations):\n",
        "    flips = np.random.binomial(n=n_flips, p=p_heads)\n",
        "    results.append(flips)\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(results, bins=range(0, n_flips+2), density=True, alpha=0.7, edgecolor='black', label='Simulated')\n",
        "\n",
        "# Overlay theoretical binomial distribution\n",
        "x = range(0, n_flips+1)\n",
        "theoretical_probs = [binom.pmf(k, n_flips, p_heads) for k in x]\n",
        "plt.plot(x, theoretical_probs, 'ro-', linewidth=2, markersize=8, label='Theoretical')\n",
        "\n",
        "plt.xlabel('Number of Heads')\n",
        "plt.ylabel('Probability')\n",
        "plt.title(f'Binomial Distribution: n={n_flips}, p={p_heads}')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Average number of heads in {n_simulations} simulations: {np.mean(results):.2f}\")\n",
        "print(f\"Expected value (n Ã— p): {n_flips * p_heads}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e__LmwBIA7gG"
      },
      "source": [
        "### ðŸŽ¯ Your Turn: Binomial Distribution\n",
        "\n",
        "A pharmaceutical company claims their drug has a 70% success rate. You're testing 20 patients.\n",
        "\n",
        "1. What's the probability of exactly 14 successes?\n",
        "2. What's the probability of 14 or more successes?\n",
        "3. What's the expected number of successes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKVdPyi9A7gG"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "n_patients = 20\n",
        "p_success = ___  # Fill in the success probability\n",
        "k_exactly = 14\n",
        "\n",
        "# 1. Probability of exactly 14 successes (use binom.pmf)\n",
        "prob_exactly_14 = binom.pmf(___, ___, ___)  # Fill in: k, n, p\n",
        "\n",
        "# 2. Probability of 14 or more successes (use 1 - binom.cdf for \"or more\")\n",
        "prob_14_or_more = 1 - binom.cdf(___, ___, ___)  # Fill in: k-1, n, p\n",
        "\n",
        "# 3. Expected number of successes\n",
        "expected_successes = n_patients * p_success\n",
        "\n",
        "print(f\"1. P(exactly 14 successes) = {prob_exactly_14:.4f}\")\n",
        "print(f\"2. P(14 or more successes) = {prob_14_or_more:.4f}\")\n",
        "print(f\"3. Expected successes = {expected_successes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYEJqWp6A7gG"
      },
      "source": [
        "---\n",
        "## Part 3: From Binomial to Normal - The Magic of Large Numbers\n",
        "\n",
        "### The Convergence Phenomenon\n",
        "\n",
        "Something remarkable happens when we increase the number of trials (n) in a binomial distribution: **it starts to look like a normal distribution!**\n",
        "\n",
        "This is why the normal distribution is so important in statistics - many real-world processes can be modeled as the sum of many small random events.\n",
        "\n",
        "Let's watch this transformation happen!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTIn_YuLA7gG"
      },
      "outputs": [],
      "source": [
        "# Visualize binomial converging to normal\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Binomial Distribution Converging to Normal Distribution', fontsize=16, fontweight='bold')\n",
        "\n",
        "p = 0.5  # probability of success\n",
        "n_values = [5, 10, 20, 50, 100, 500]  # different numbers of trials\n",
        "\n",
        "for idx, n in enumerate(n_values):\n",
        "    ax = axes[idx // 3, idx % 3]\n",
        "\n",
        "    # Binomial distribution\n",
        "    x = np.arange(0, n+1)\n",
        "    binomial_probs = binom.pmf(x, n, p)\n",
        "\n",
        "    # Normal approximation\n",
        "    mu = n * p  # mean\n",
        "    sigma = np.sqrt(n * p * (1-p))  # standard deviation\n",
        "    x_norm = np.linspace(0, n, 1000)\n",
        "    normal_probs = norm.pdf(x_norm, mu, sigma)\n",
        "\n",
        "    # Plot\n",
        "    ax.bar(x, binomial_probs, alpha=0.6, label='Binomial', edgecolor='black')\n",
        "    ax.plot(x_norm, normal_probs, 'r-', linewidth=2, label='Normal Approximation')\n",
        "    ax.set_title(f'n = {n}')\n",
        "    ax.set_xlabel('Number of Successes')\n",
        "    ax.set_ylabel('Probability')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nðŸ“Š Notice how the binomial distribution becomes smoother and more bell-shaped as n increases!\")\n",
        "print(\"This is the foundation for using the normal distribution in hypothesis testing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfgpcO5EA7gH"
      },
      "source": [
        "### ðŸŽ¯ Your Turn: Explore the Convergence\n",
        "\n",
        "Modify the value of `p` below to see how convergence happens for different success probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRS9O9rrA7gH"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE: Try different values of p (between 0 and 1)\n",
        "# Try: 0.1, 0.3, 0.5, 0.7, 0.9\n",
        "p = ___  # Try different values!\n",
        "n = 100\n",
        "\n",
        "x = np.arange(0, n+1)\n",
        "binomial_probs = binom.pmf(x, n, p)\n",
        "\n",
        "mu = n * p\n",
        "sigma = np.sqrt(n * p * (1-p))\n",
        "x_norm = np.linspace(0, n, 1000)\n",
        "normal_probs = norm.pdf(x_norm, mu, sigma)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(x, binomial_probs, alpha=0.6, label=f'Binomial (n={n}, p={p})', edgecolor='black')\n",
        "plt.plot(x_norm, normal_probs, 'r-', linewidth=2, label='Normal Approximation')\n",
        "plt.xlabel('Number of Successes')\n",
        "plt.ylabel('Probability')\n",
        "plt.title(f'Convergence with p = {p}')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Note: Convergence is fastest when p = 0.5 (symmetric distribution)\")\n",
        "print(f\"It's slower when p is near 0 or 1 (skewed distribution)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRDKEOTOA7gH"
      },
      "source": [
        "---\n",
        "## Part 4: Least Squares Estimation - Finding the Best Fit\n",
        "\n",
        "### What is Least Squares?\n",
        "\n",
        "**Least Squares** is a method for estimating parameters by minimizing the sum of squared differences between observed and predicted values.\n",
        "\n",
        "**Why \"Squared\"?**\n",
        "- Squaring makes all errors positive\n",
        "- It penalizes large errors more than small ones\n",
        "- It has nice mathematical properties (differentiable, unique solution)\n",
        "\n",
        "### Example: Estimating the Mean\n",
        "\n",
        "The sample mean is actually a least squares estimator! It minimizes the sum of squared deviations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0aOwbnkA7gH"
      },
      "outputs": [],
      "source": [
        "# Generate some data\n",
        "data = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20])\n",
        "\n",
        "# Try different estimates and calculate sum of squared errors\n",
        "possible_means = np.linspace(5, 15, 100)\n",
        "squared_errors = []\n",
        "\n",
        "for candidate_mean in possible_means:\n",
        "    errors = data - candidate_mean\n",
        "    sse = np.sum(errors**2)  # Sum of Squared Errors\n",
        "    squared_errors.append(sse)\n",
        "\n",
        "# The true mean minimizes the sum of squared errors\n",
        "true_mean = np.mean(data)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(possible_means, squared_errors, 'b-', linewidth=2)\n",
        "plt.axvline(true_mean, color='r', linestyle='--', linewidth=2, label=f'Sample Mean = {true_mean}')\n",
        "plt.xlabel('Candidate Mean Value')\n",
        "plt.ylabel('Sum of Squared Errors')\n",
        "plt.title('Least Squares: The Mean Minimizes Squared Errors')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Sample mean (least squares estimate): {true_mean}\")\n",
        "print(f\"This is the value that minimizes the sum of squared errors!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNnuEy7zA7gH"
      },
      "source": [
        "### ðŸŽ¯ Your Turn: Least Squares for Linear Regression\n",
        "\n",
        "Let's fit a line to some data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Gsbds_sA7gH"
      },
      "outputs": [],
      "source": [
        "# Generate data with a linear relationship plus noise\n",
        "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "y = 2 * x + 3 + np.random.normal(0, 2, size=len(x))  # y = 2x + 3 + noise\n",
        "\n",
        "# YOUR CODE HERE: Calculate least squares estimates for slope and intercept\n",
        "# Hint: slope = covariance(x,y) / variance(x)\n",
        "#       intercept = mean(y) - slope * mean(x)\n",
        "\n",
        "x_mean = np.mean(x)\n",
        "y_mean = np.mean(y)\n",
        "\n",
        "slope = np.sum((x - x_mean) * (y - y_mean)) / np.sum((x - x_mean)**2)\n",
        "intercept = ___  # Calculate the intercept\n",
        "\n",
        "# Predictions\n",
        "y_pred = slope * x + intercept\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x, y, s=100, alpha=0.6, label='Data Points')\n",
        "plt.plot(x, y_pred, 'r-', linewidth=2, label=f'Best Fit: y = {slope:.2f}x + {intercept:.2f}')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Least Squares Linear Regression')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Estimated slope: {slope:.3f}\")\n",
        "print(f\"Estimated intercept: {intercept:.3f}\")\n",
        "print(f\"(True values were: slope=2, intercept=3)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg5Gd4t1A7gH"
      },
      "source": [
        "---\n",
        "## Part 5: Maximum Likelihood Estimation (MLE)\n",
        "\n",
        "### What is Maximum Likelihood?\n",
        "\n",
        "**Maximum Likelihood Estimation** finds parameter values that make the observed data most probable (most \"likely\").\n",
        "\n",
        "**The Idea**:\n",
        "- Given data, what parameter values would make this data most likely to occur?\n",
        "- We find the parameters that maximize the likelihood function\n",
        "\n",
        "### Example: Estimating Coin Bias\n",
        "\n",
        "Suppose we flip a coin 10 times and get 7 heads. What's the most likely probability of heads?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC26kztTA7gH"
      },
      "outputs": [],
      "source": [
        "# Data: 7 heads out of 10 flips\n",
        "n_flips = 10\n",
        "n_heads = 7\n",
        "\n",
        "# Try different values of p (probability of heads)\n",
        "p_values = np.linspace(0.01, 0.99, 100)\n",
        "likelihoods = []\n",
        "\n",
        "for p in p_values:\n",
        "    # Likelihood: probability of observing 7 heads in 10 flips given p\n",
        "    likelihood = binom.pmf(n_heads, n_flips, p)\n",
        "    likelihoods.append(likelihood)\n",
        "\n",
        "# Maximum likelihood estimate\n",
        "mle_p = p_values[np.argmax(likelihoods)]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(p_values, likelihoods, 'b-', linewidth=2)\n",
        "plt.axvline(mle_p, color='r', linestyle='--', linewidth=2,\n",
        "            label=f'MLE = {mle_p:.3f}')\n",
        "plt.axvline(n_heads/n_flips, color='g', linestyle='--', linewidth=2,\n",
        "            label=f'Sample Proportion = {n_heads/n_flips:.1f}')\n",
        "plt.xlabel('Probability of Heads (p)')\n",
        "plt.ylabel('Likelihood')\n",
        "plt.title('Maximum Likelihood Estimation for Coin Flip')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Maximum Likelihood Estimate: p = {mle_p:.3f}\")\n",
        "print(f\"Sample proportion: {n_heads}/{n_flips} = {n_heads/n_flips:.1f}\")\n",
        "print(f\"\\nFor binomial data, the MLE equals the sample proportion!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEr51TaxA7gH"
      },
      "source": [
        "### ðŸŽ¯ Your Turn: MLE for Normal Distribution\n",
        "\n",
        "Given data from a normal distribution, find the MLE for the mean (Î¼)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2geah6_A7gH"
      },
      "outputs": [],
      "source": [
        "# Generate data from a normal distribution\n",
        "true_mean = 50\n",
        "true_std = 10\n",
        "data = np.random.normal(true_mean, true_std, size=100)\n",
        "\n",
        "# Try different values of mean\n",
        "mean_values = np.linspace(40, 60, 100)\n",
        "log_likelihoods = []  # We use log-likelihood for numerical stability\n",
        "\n",
        "for mu in mean_values:\n",
        "    # Log-likelihood: sum of log probabilities\n",
        "    log_lik = np.sum(norm.logpdf(data, mu, true_std))\n",
        "    log_likelihoods.append(log_lik)\n",
        "\n",
        "# Maximum likelihood estimate\n",
        "mle_mean = mean_values[np.argmax(log_likelihoods)]\n",
        "\n",
        "# YOUR CODE HERE: Calculate the sample mean\n",
        "sample_mean = ___  # Use np.mean()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(mean_values, log_likelihoods, 'b-', linewidth=2)\n",
        "plt.axvline(mle_mean, color='r', linestyle='--', linewidth=2, label=f'MLE = {mle_mean:.2f}')\n",
        "plt.axvline(sample_mean, color='g', linestyle='--', linewidth=2, label=f'Sample Mean = {sample_mean:.2f}')\n",
        "plt.axvline(true_mean, color='orange', linestyle='--', linewidth=2, label=f'True Mean = {true_mean}')\n",
        "plt.xlabel('Mean (Î¼)')\n",
        "plt.ylabel('Log-Likelihood')\n",
        "plt.title('MLE for Normal Distribution Mean')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Maximum Likelihood Estimate: Î¼ = {mle_mean:.2f}\")\n",
        "print(f\"Sample mean: {sample_mean:.2f}\")\n",
        "print(f\"True mean: {true_mean}\")\n",
        "print(f\"\\nFor normal data, the MLE for Î¼ equals the sample mean!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-FzLgMPA7gH"
      },
      "source": [
        "### Connection to Hypothesis Testing\n",
        "\n",
        "Both Least Squares and MLE are used to estimate parameters from data. In hypothesis testing:\n",
        "- We estimate parameters from our sample\n",
        "- We compare these estimates to hypothesized values\n",
        "- We determine if the difference is statistically significant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVYhsvBgA7gH"
      },
      "source": [
        "---\n",
        "## Part 6: Conditional Probability - Updating Beliefs\n",
        "\n",
        "### What is Conditional Probability?\n",
        "\n",
        "**Conditional Probability** P(A|B) is the probability of event A occurring given that event B has occurred.\n",
        "\n",
        "**Formula**: P(A|B) = P(A âˆ© B) / P(B)\n",
        "\n",
        "**Bayes' Theorem**: P(A|B) = P(B|A) Ã— P(A) / P(B)\n",
        "\n",
        "### Example: Medical Testing\n",
        "\n",
        "A disease affects 1% of the population. A test is 95% accurate (95% sensitivity and 95% specificity).\n",
        "If you test positive, what's the probability you actually have the disease?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzxwzgoNA7gH"
      },
      "outputs": [],
      "source": [
        "# Define probabilities\n",
        "p_disease = 0.01  # P(Disease) - prevalence\n",
        "p_positive_given_disease = 0.95  # P(Positive|Disease) - sensitivity\n",
        "p_negative_given_no_disease = 0.95  # P(Negative|No Disease) - specificity\n",
        "p_positive_given_no_disease = 1 - p_negative_given_no_disease  # False positive rate\n",
        "\n",
        "# Calculate P(Positive) using law of total probability\n",
        "p_positive = (p_positive_given_disease * p_disease +\n",
        "              p_positive_given_no_disease * (1 - p_disease))\n",
        "\n",
        "# Apply Bayes' theorem: P(Disease|Positive)\n",
        "p_disease_given_positive = (p_positive_given_disease * p_disease) / p_positive\n",
        "\n",
        "print(\"Medical Test Analysis\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Disease prevalence: {p_disease*100}%\")\n",
        "print(f\"Test sensitivity (true positive rate): {p_positive_given_disease*100}%\")\n",
        "print(f\"Test specificity (true negative rate): {p_negative_given_no_disease*100}%\")\n",
        "print(f\"\\nP(Positive test) = {p_positive:.4f}\")\n",
        "print(f\"P(Disease|Positive test) = {p_disease_given_positive:.4f} or {p_disease_given_positive*100:.2f}%\")\n",
        "print(f\"\\nâš ï¸ Even with a positive test, you only have a {p_disease_given_positive*100:.1f}% chance of having the disease!\")\n",
        "print(f\"This is because the disease is rare (base rate fallacy).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7TUB5avA7gH"
      },
      "source": [
        "### ðŸŽ¯ Your Turn: Conditional Probability\n",
        "\n",
        "In a factory, Machine A produces 60% of items and Machine B produces 40%.\n",
        "- Machine A has a 2% defect rate\n",
        "- Machine B has a 5% defect rate\n",
        "\n",
        "If a randomly selected item is defective, what's the probability it came from Machine A?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03JrF3oXA7gH"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "p_machine_a = ___  # Fill in\n",
        "p_machine_b = ___  # Fill in\n",
        "p_defect_given_a = ___  # Fill in\n",
        "p_defect_given_b = ___  # Fill in\n",
        "\n",
        "# Calculate P(Defect) using law of total probability\n",
        "p_defect = (p_defect_given_a * p_machine_a +\n",
        "            p_defect_given_b * p_machine_b)\n",
        "\n",
        "# Calculate P(Machine A | Defect) using Bayes' theorem\n",
        "p_a_given_defect = (p_defect_given_a * p_machine_a) / p_defect\n",
        "\n",
        "print(f\"P(Defect) = {p_defect:.4f}\")\n",
        "print(f\"P(Machine A | Defect) = {p_a_given_defect:.4f} or {p_a_given_defect*100:.2f}%\")\n",
        "print(f\"P(Machine B | Defect) = {1-p_a_given_defect:.4f} or {(1-p_a_given_defect)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49aYM6-FA7gI"
      },
      "source": [
        "---\n",
        "## Part 7: Distribution Functions - PDF, PMF, CDF, PPF, KDE\n",
        "\n",
        "### Understanding Different Distribution Functions\n",
        "\n",
        "These are different ways to describe probability distributions:\n",
        "\n",
        "**PMF (Probability Mass Function)**: For discrete distributions\n",
        "- Gives P(X = k) for specific values\n",
        "- Example: Probability of exactly 3 heads in 10 flips\n",
        "\n",
        "**PDF (Probability Density Function)**: For continuous distributions  \n",
        "- Describes relative likelihood at a point\n",
        "- NOT a probability! Must integrate over a range\n",
        "\n",
        "**CDF (Cumulative Distribution Function)**: For any distribution\n",
        "- Gives P(X â‰¤ x)\n",
        "- Increases from 0 to 1\n",
        "\n",
        "**PPF (Percent Point Function)**: Inverse of CDF\n",
        "- Given a probability, returns the corresponding value\n",
        "- Also called quantile function\n",
        "\n",
        "**KDE (Kernel Density Estimate)**: Smooth estimate of PDF from data\n",
        "- Non-parametric method\n",
        "\n",
        "Let's visualize all of these!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffvErI5CA7gI"
      },
      "outputs": [],
      "source": [
        "# Create figure with subplots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "fig.suptitle('Understanding Distribution Functions', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. PMF - Discrete (Binomial)\n",
        "ax1 = axes[0, 0]\n",
        "n, p = 20, 0.5\n",
        "x_discrete = np.arange(0, n+1)\n",
        "pmf_values = binom.pmf(x_discrete, n, p)\n",
        "ax1.bar(x_discrete, pmf_values, alpha=0.7, edgecolor='black')\n",
        "ax1.set_title('PMF: Probability Mass Function\\n(Discrete)')\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('P(X = x)')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# 2. PDF - Continuous (Normal)\n",
        "ax2 = axes[0, 1]\n",
        "x_continuous = np.linspace(-4, 4, 1000)\n",
        "pdf_values = norm.pdf(x_continuous, 0, 1)\n",
        "ax2.plot(x_continuous, pdf_values, 'b-', linewidth=2)\n",
        "ax2.fill_between(x_continuous, pdf_values, alpha=0.3)\n",
        "ax2.set_title('PDF: Probability Density Function\\n(Continuous)')\n",
        "ax2.set_xlabel('x')\n",
        "ax2.set_ylabel('f(x)')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# 3. CDF - Discrete\n",
        "ax3 = axes[0, 2]\n",
        "cdf_values_discrete = binom.cdf(x_discrete, n, p)\n",
        "ax3.step(x_discrete, cdf_values_discrete, where='post', linewidth=2)\n",
        "ax3.set_title('CDF: Cumulative Distribution\\n(Discrete)')\n",
        "ax3.set_xlabel('x')\n",
        "ax3.set_ylabel('P(X â‰¤ x)')\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# 4. CDF - Continuous\n",
        "ax4 = axes[1, 0]\n",
        "cdf_values_continuous = norm.cdf(x_continuous, 0, 1)\n",
        "ax4.plot(x_continuous, cdf_values_continuous, 'b-', linewidth=2)\n",
        "ax4.set_title('CDF: Cumulative Distribution\\n(Continuous)')\n",
        "ax4.set_xlabel('x')\n",
        "ax4.set_ylabel('P(X â‰¤ x)')\n",
        "ax4.grid(alpha=0.3)\n",
        "\n",
        "# 5. PPF - Percent Point Function (Inverse CDF)\n",
        "ax5 = axes[1, 1]\n",
        "probabilities = np.linspace(0.01, 0.99, 1000)\n",
        "ppf_values = norm.ppf(probabilities, 0, 1)\n",
        "ax5.plot(probabilities, ppf_values, 'r-', linewidth=2)\n",
        "ax5.set_title('PPF: Percent Point Function\\n(Inverse of CDF)')\n",
        "ax5.set_xlabel('Probability')\n",
        "ax5.set_ylabel('x value')\n",
        "ax5.grid(alpha=0.3)\n",
        "\n",
        "# 6. KDE - Kernel Density Estimate\n",
        "ax6 = axes[1, 2]\n",
        "# Generate sample data\n",
        "sample_data = np.random.normal(0, 1, 1000)\n",
        "# Calculate KDE\n",
        "kde = gaussian_kde(sample_data)\n",
        "x_kde = np.linspace(-4, 4, 1000)\n",
        "kde_values = kde(x_kde)\n",
        "ax6.hist(sample_data, bins=30, density=True, alpha=0.5, label='Histogram')\n",
        "ax6.plot(x_kde, kde_values, 'r-', linewidth=2, label='KDE')\n",
        "ax6.plot(x_kde, norm.pdf(x_kde, 0, 1), 'g--', linewidth=2, label='True PDF')\n",
        "ax6.set_title('KDE: Kernel Density Estimate\\n(Non-parametric)')\n",
        "ax6.set_xlabel('x')\n",
        "ax6.set_ylabel('Density')\n",
        "ax6.legend()\n",
        "ax6.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a55fbcKvA7gI"
      },
      "source": [
        "### ðŸŽ¯ Your Turn: Working with Distribution Functions\n",
        "\n",
        "Answer these questions using the appropriate distribution function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKa3KDKIA7gI"
      },
      "outputs": [],
      "source": [
        "# Question 1: What is P(X = 15) for a binomial with n=20, p=0.7?\n",
        "# Use PMF\n",
        "q1_answer = binom.pmf(___, ___, ___)  # Fill in: k, n, p\n",
        "print(f\"Q1: P(X = 15) = {q1_answer:.4f}\")\n",
        "\n",
        "# Question 2: What is P(Z â‰¤ 1.96) for a standard normal?\n",
        "# Use CDF\n",
        "q2_answer = norm.cdf(___)  # Fill in the z-value\n",
        "print(f\"Q2: P(Z â‰¤ 1.96) = {q2_answer:.4f}\")\n",
        "\n",
        "# Question 3: What z-value has 95% of the distribution below it?\n",
        "# Use PPF\n",
        "q3_answer = norm.ppf(___)  # Fill in the probability\n",
        "print(f\"Q3: z-value for 95th percentile = {q3_answer:.4f}\")\n",
        "\n",
        "# Question 4: What is the density at z=0 for a standard normal?\n",
        "# Use PDF\n",
        "q4_answer = norm.pdf(___)\n",
        "print(f\"Q4: Density at z=0 = {q4_answer:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z3yiVJSA7gI"
      },
      "source": [
        "---\n",
        "## Part 8: Law of Large Numbers - Stability Through Repetition\n",
        "\n",
        "### What is the Law of Large Numbers?\n",
        "\n",
        "The **Law of Large Numbers** (LLN) states that as the sample size increases, the sample mean converges to the population mean.\n",
        "\n",
        "**In simple terms**: The more data you collect, the closer your sample average gets to the true average.\n",
        "\n",
        "This is why casinos always win in the long run - individual bets are random, but over thousands of bets, the average outcome approaches the expected value.\n",
        "\n",
        "Let's see it in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQEUMWKaA7gI"
      },
      "outputs": [],
      "source": [
        "# Simulate rolling a fair die\n",
        "true_mean = 3.5  # Expected value of a fair die: (1+2+3+4+5+6)/6\n",
        "n_rolls = 10000\n",
        "\n",
        "# Generate random die rolls\n",
        "rolls = np.random.randint(1, 7, size=n_rolls)\n",
        "\n",
        "# Calculate cumulative average\n",
        "cumulative_average = np.cumsum(rolls) / np.arange(1, n_rolls + 1)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(cumulative_average, linewidth=1, alpha=0.7, label='Sample Mean')\n",
        "plt.axhline(true_mean, color='r', linestyle='--', linewidth=2, label=f'True Mean = {true_mean}')\n",
        "plt.xlabel('Number of Rolls')\n",
        "plt.ylabel('Cumulative Average')\n",
        "plt.title('Law of Large Numbers: Die Rolling')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.xscale('log')  # Log scale to see both early and late behavior\n",
        "plt.show()\n",
        "\n",
        "print(f\"After 10 rolls: average = {cumulative_average[9]:.3f}\")\n",
        "print(f\"After 100 rolls: average = {cumulative_average[99]:.3f}\")\n",
        "print(f\"After 1000 rolls: average = {cumulative_average[999]:.3f}\")\n",
        "print(f\"After 10000 rolls: average = {cumulative_average[9999]:.3f}\")\n",
        "print(f\"\\nTrue mean: {true_mean}\")\n",
        "print(f\"\\nðŸ“Š Notice how the sample mean gets closer to 3.5 as we roll more!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyIPovAOA7gI"
      },
      "source": [
        "### ðŸŽ¯ Your Turn: Verify LLN with Coin Flips\n",
        "\n",
        "Simulate coin flips and watch the proportion of heads converge to 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_Ym2A9iA7gI"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "n_flips = 10000\n",
        "true_prob_heads = 0.5\n",
        "\n",
        "# Simulate coin flips (0 = tails, 1 = heads)\n",
        "flips = np.random.binomial(1, true_prob_heads, size=n_flips)\n",
        "\n",
        "# Calculate cumulative proportion of heads\n",
        "cumulative_proportion = np.cumsum(flips) / np.arange(1, n_flips + 1)\n",
        "\n",
        "# Plot (you complete this)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(___, linewidth=1, alpha=0.7, label='Sample Proportion')  # Fill in\n",
        "plt.axhline(___, color='r', linestyle='--', linewidth=2, label='True Probability')  # Fill in\n",
        "plt.xlabel('Number of Flips')\n",
        "plt.ylabel('Proportion of Heads')\n",
        "plt.title('Law of Large Numbers: Coin Flipping')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.xscale('log')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final proportion after {n_flips} flips: {cumulative_proportion[-1]:.4f}\")\n",
        "print(f\"True probability: {true_prob_heads}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZALfAmqA7gI"
      },
      "source": [
        "---\n",
        "## Part 9: Central Limit Theorem - The Foundation of Inference\n",
        "\n",
        "### What is the Central Limit Theorem?\n",
        "\n",
        "The **Central Limit Theorem** (CLT) states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, **regardless of the shape of the population distribution**.\n",
        "\n",
        "**Key Points**:\n",
        "1. The mean of the sampling distribution equals the population mean (Î¼)\n",
        "2. The standard deviation of the sampling distribution (standard error) is Ïƒ/âˆšn\n",
        "3. This works even if the population is not normally distributed!\n",
        "\n",
        "**Why This Matters**: This is the reason we can use normal distribution-based tests (z-tests, t-tests) even when our data isn't normally distributed!\n",
        "\n",
        "Let's demonstrate with a very non-normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmv2DhaBA7gI"
      },
      "outputs": [],
      "source": [
        "# Start with a highly skewed distribution (exponential)\n",
        "population_mean = 5\n",
        "population = np.random.exponential(population_mean, size=100000)\n",
        "\n",
        "# Take samples of different sizes and compute their means\n",
        "sample_sizes = [2, 5, 10, 30, 100]\n",
        "n_samples = 10000\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "fig.suptitle('Central Limit Theorem in Action', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Plot the population distribution\n",
        "ax0 = axes[0, 0]\n",
        "ax0.hist(population[:1000], bins=50, density=True, alpha=0.7, edgecolor='black')\n",
        "ax0.axvline(population_mean, color='r', linestyle='--', linewidth=2, label=f'Mean = {population_mean}')\n",
        "ax0.set_title('Population Distribution\\n(Highly Skewed!)')\n",
        "ax0.set_xlabel('Value')\n",
        "ax0.set_ylabel('Density')\n",
        "ax0.legend()\n",
        "ax0.grid(alpha=0.3)\n",
        "\n",
        "# Plot sampling distributions for different sample sizes\n",
        "for idx, n in enumerate(sample_sizes):\n",
        "    ax = axes[(idx+1)//3, (idx+1)%3]\n",
        "\n",
        "    # Take many samples and compute their means\n",
        "    sample_means = []\n",
        "    for _ in range(n_samples):\n",
        "        sample = np.random.exponential(population_mean, size=n)\n",
        "        sample_means.append(np.mean(sample))\n",
        "\n",
        "    sample_means = np.array(sample_means)\n",
        "\n",
        "    # Plot histogram of sample means\n",
        "    ax.hist(sample_means, bins=50, density=True, alpha=0.7, edgecolor='black', label='Sample Means')\n",
        "\n",
        "    # Overlay theoretical normal distribution\n",
        "    x = np.linspace(sample_means.min(), sample_means.max(), 100)\n",
        "    theoretical_std = population_mean / np.sqrt(n)  # Standard error\n",
        "    ax.plot(x, norm.pdf(x, population_mean, theoretical_std), 'r-',\n",
        "            linewidth=2, label='Theoretical Normal')\n",
        "\n",
        "    ax.set_title(f'Sampling Distribution\\nn = {n}')\n",
        "    ax.set_xlabel('Sample Mean')\n",
        "    ax.set_ylabel('Density')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nðŸŽ¯ Key Observations:\")\n",
        "print(\"1. The population is highly skewed (not normal!)\")\n",
        "print(\"2. As sample size increases, the distribution of sample means becomes more normal\")\n",
        "print(\"3. The distribution gets narrower (smaller standard error) as n increases\")\n",
        "print(\"4. By n=30, the sampling distribution is quite normal!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7EFntm0A7gK"
      },
      "source": [
        "### ðŸŽ¯ Your Turn: Verify Standard Error Formula\n",
        "\n",
        "Verify that the standard deviation of sample means equals Ïƒ/âˆšn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO7db_whA7gK"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "population_std = 10\n",
        "sample_size = 25\n",
        "n_samples = 10000\n",
        "\n",
        "# Generate population\n",
        "population = np.random.normal(50, population_std, size=100000)\n",
        "\n",
        "# Take many samples and compute their means\n",
        "sample_means = []\n",
        "for _ in range(n_samples):\n",
        "    sample = np.random.choice(population, size=sample_size)\n",
        "    sample_means.append(np.mean(sample))\n",
        "\n",
        "# Calculate observed standard error (standard deviation of sample means)\n",
        "observed_se = np.std(sample_means)\n",
        "\n",
        "# Calculate theoretical standard error\n",
        "theoretical_se = population_std / np.sqrt(sample_size)\n",
        "\n",
        "print(f\"Observed standard error: {observed_se:.4f}\")\n",
        "print(f\"Theoretical standard error (Ïƒ/âˆšn): {theoretical_se:.4f}\")\n",
        "print(f\"Difference: {abs(observed_se - theoretical_se):.4f}\")\n",
        "print(f\"\\nâœ“ They match! (within simulation error)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMUguWUTA7gK"
      },
      "source": [
        "---\n",
        "## Part 10: Hypothesis Testing - Putting It All Together\n",
        "\n",
        "### The Framework of Hypothesis Testing\n",
        "\n",
        "Now we have all the pieces we need! Hypothesis testing is a formal procedure for making decisions about population parameters based on sample data.\n",
        "\n",
        "### The Components:\n",
        "\n",
        "1. **Null Hypothesis (Hâ‚€)**: The default claim (usually \"no effect\" or \"no difference\")\n",
        "2. **Alternative Hypothesis (Hâ‚)**: What we're testing for (the claim we want evidence for)\n",
        "3. **Significance Level (Î±)**: The probability of rejecting Hâ‚€ when it's true (Type I error)\n",
        "4. **Test Statistic**: A value calculated from sample data\n",
        "5. **Critical Value**: The threshold for the test statistic\n",
        "6. **Region of Rejection**: Values of the test statistic that lead to rejecting Hâ‚€\n",
        "7. **P-value**: The probability of getting results as extreme as observed, assuming Hâ‚€ is true\n",
        "8. **Type I Error (Î±)**: Rejecting true Hâ‚€ (false positive)\n",
        "9. **Type II Error (Î²)**: Failing to reject false Hâ‚€ (false negative)\n",
        "\n",
        "### The Process:\n",
        "\n",
        "```\n",
        "1. State hypotheses (Hâ‚€ and Hâ‚)\n",
        "2. Choose significance level (Î±)\n",
        "3. Collect data and calculate test statistic\n",
        "4. Determine critical value or p-value\n",
        "5. Make decision: reject or fail to reject Hâ‚€\n",
        "6. Draw conclusion in context\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvvVSNeCA7gK"
      },
      "source": [
        "### Example: Testing a New Drug\n",
        "\n",
        "A pharmaceutical company claims their new drug lowers blood pressure by more than 10 points on average. Let's test this claim!\n",
        "\n",
        "**Setup**:\n",
        "- Hâ‚€: Î¼ â‰¤ 10 (drug lowers BP by 10 or fewer points)\n",
        "- Hâ‚: Î¼ > 10 (drug lowers BP by more than 10 points)\n",
        "- Î± = 0.05 (5% significance level)\n",
        "- We test 100 patients and find: mean reduction = 12.5, std = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwBh_QIUA7gL"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "sample_mean = 12.5  # observed mean reduction in BP\n",
        "hypothesized_mean = 10  # value under null hypothesis\n",
        "sample_std = 5\n",
        "n = 100\n",
        "alpha = 0.05\n",
        "\n",
        "# Calculate test statistic (z-score)\n",
        "# z = (sample_mean - hypothesized_mean) / (sample_std / sqrt(n))\n",
        "standard_error = sample_std / np.sqrt(n)\n",
        "z_statistic = (sample_mean - hypothesized_mean) / standard_error\n",
        "\n",
        "# Calculate critical value (one-tailed test)\n",
        "z_critical = norm.ppf(1 - alpha)\n",
        "\n",
        "# Calculate p-value\n",
        "p_value = 1 - norm.cdf(z_statistic)\n",
        "\n",
        "# Visualize\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Left plot: Critical value approach\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "ax1.plot(x, y, 'b-', linewidth=2, label='Null Distribution')\n",
        "ax1.fill_between(x[x >= z_critical], y[x >= z_critical], alpha=0.3, color='red',\n",
        "                  label=f'Rejection Region (Î±={alpha})')\n",
        "ax1.axvline(z_statistic, color='green', linestyle='--', linewidth=2,\n",
        "            label=f'Test Statistic = {z_statistic:.2f}')\n",
        "ax1.axvline(z_critical, color='red', linestyle='--', linewidth=2,\n",
        "            label=f'Critical Value = {z_critical:.2f}')\n",
        "ax1.set_xlabel('Z-score')\n",
        "ax1.set_ylabel('Density')\n",
        "ax1.set_title('Critical Value Approach')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Right plot: P-value approach\n",
        "ax2.plot(x, y, 'b-', linewidth=2, label='Null Distribution')\n",
        "ax2.fill_between(x[x >= z_statistic], y[x >= z_statistic], alpha=0.3, color='orange',\n",
        "                  label=f'P-value = {p_value:.4f}')\n",
        "ax2.axvline(z_statistic, color='green', linestyle='--', linewidth=2,\n",
        "            label=f'Test Statistic = {z_statistic:.2f}')\n",
        "ax2.set_xlabel('Z-score')\n",
        "ax2.set_ylabel('Density')\n",
        "ax2.set_title('P-value Approach')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"HYPOTHESIS TEST RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nNull Hypothesis (Hâ‚€): Î¼ â‰¤ {hypothesized_mean}\")\n",
        "print(f\"Alternative Hypothesis (Hâ‚): Î¼ > {hypothesized_mean}\")\n",
        "print(f\"Significance Level (Î±): {alpha}\")\n",
        "print(f\"\\nSample Statistics:\")\n",
        "print(f\"  Sample Mean: {sample_mean}\")\n",
        "print(f\"  Sample Std: {sample_std}\")\n",
        "print(f\"  Sample Size: {n}\")\n",
        "print(f\"  Standard Error: {standard_error:.4f}\")\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"  Test Statistic (z): {z_statistic:.4f}\")\n",
        "print(f\"  Critical Value: {z_critical:.4f}\")\n",
        "print(f\"  P-value: {p_value:.4f}\")\n",
        "print(f\"\\nDecision:\")\n",
        "if p_value < alpha:\n",
        "    print(f\"  âœ“ Reject Hâ‚€ (p-value {p_value:.4f} < Î± {alpha})\")\n",
        "    print(f\"  âœ“ Test statistic {z_statistic:.2f} > critical value {z_critical:.2f}\")\n",
        "else:\n",
        "    print(f\"  âœ— Fail to reject Hâ‚€ (p-value {p_value:.4f} â‰¥ Î± {alpha})\")\n",
        "    print(f\"  âœ— Test statistic {z_statistic:.2f} â‰¤ critical value {z_critical:.2f}\")\n",
        "print(f\"\\nConclusion:\")\n",
        "if p_value < alpha:\n",
        "    print(f\"  There is sufficient evidence to conclude that the drug lowers\")\n",
        "    print(f\"  blood pressure by more than 10 points on average.\")\n",
        "else:\n",
        "    print(f\"  There is insufficient evidence to conclude that the drug lowers\")\n",
        "    print(f\"  blood pressure by more than 10 points on average.\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dpsM0W0A7gL"
      },
      "source": [
        "### Understanding Type I and Type II Errors\n",
        "\n",
        "Let's visualize what these errors mean:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLmlLVnWA7gL"
      },
      "outputs": [],
      "source": [
        "# Visualize Type I and Type II errors\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Setup\n",
        "mu0 = 0  # null hypothesis mean\n",
        "mu1 = 2  # true mean (alternative)\n",
        "sigma = 1\n",
        "alpha = 0.05\n",
        "critical_value = norm.ppf(1 - alpha)\n",
        "\n",
        "x = np.linspace(-3, 5, 1000)\n",
        "y_null = norm.pdf(x, mu0, sigma)\n",
        "y_alt = norm.pdf(x, mu1, sigma)\n",
        "\n",
        "# Type I Error (Î±)\n",
        "ax1.plot(x, y_null, 'b-', linewidth=2, label='Hâ‚€ is True')\n",
        "ax1.fill_between(x[x >= critical_value], y_null[x >= critical_value],\n",
        "                  alpha=0.5, color='red', label=f'Type I Error (Î± = {alpha})')\n",
        "ax1.axvline(critical_value, color='red', linestyle='--', linewidth=2,\n",
        "            label=f'Critical Value')\n",
        "ax1.set_xlabel('Test Statistic')\n",
        "ax1.set_ylabel('Density')\n",
        "ax1.set_title('Type I Error: Rejecting True Hâ‚€\\n(False Positive)')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Type II Error (Î²)\n",
        "ax2.plot(x, y_alt, 'g-', linewidth=2, label='Hâ‚€ is False (Hâ‚ is True)')\n",
        "ax2.fill_between(x[x < critical_value], y_alt[x < critical_value],\n",
        "                  alpha=0.5, color='orange', label='Type II Error (Î²)')\n",
        "ax2.fill_between(x[x >= critical_value], y_alt[x >= critical_value],\n",
        "                  alpha=0.5, color='lightgreen', label='Power (1-Î²)')\n",
        "ax2.axvline(critical_value, color='red', linestyle='--', linewidth=2,\n",
        "            label='Critical Value')\n",
        "ax2.set_xlabel('Test Statistic')\n",
        "ax2.set_ylabel('Density')\n",
        "ax2.set_title('Type II Error: Failing to Reject False Hâ‚€\\n(False Negative)')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate Î²\n",
        "beta = norm.cdf(critical_value, mu1, sigma)\n",
        "power = 1 - beta\n",
        "\n",
        "print(\"\\nðŸ“Š Error Types:\")\n",
        "print(f\"Type I Error (Î±): {alpha} - Probability of false positive\")\n",
        "print(f\"Type II Error (Î²): {beta:.4f} - Probability of false negative\")\n",
        "print(f\"Power (1-Î²): {power:.4f} - Probability of correctly rejecting false Hâ‚€\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Truth Table:\")\n",
        "print(\"=\"*70)\n",
        "print(\"                    â”‚  Hâ‚€ is True    â”‚  Hâ‚€ is False   â”‚\")\n",
        "print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚\")\n",
        "print(\"Fail to Reject Hâ‚€   â”‚  Correct âœ“     â”‚  Type II (Î²)   â”‚\")\n",
        "print(\"Reject Hâ‚€           â”‚  Type I (Î±)    â”‚  Correct âœ“     â”‚\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3Ee7Fy3A7gL"
      },
      "source": [
        "### Confidence Intervals - Another Perspective\n",
        "\n",
        "A confidence interval gives us a range of plausible values for the population parameter.\n",
        "\n",
        "**95% Confidence Interval**: If we repeated the sampling process many times, 95% of the intervals would contain the true parameter.\n",
        "\n",
        "**Formula**: sample_mean Â± (critical_value Ã— standard_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS68yGqDA7gL"
      },
      "outputs": [],
      "source": [
        "# Calculate 95% confidence interval for our drug example\n",
        "confidence_level = 0.95\n",
        "alpha_ci = 1 - confidence_level\n",
        "z_critical_ci = norm.ppf(1 - alpha_ci/2)  # Two-tailed\n",
        "\n",
        "margin_of_error = z_critical_ci * standard_error\n",
        "ci_lower = sample_mean - margin_of_error\n",
        "ci_upper = sample_mean + margin_of_error\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Point estimate\n",
        "plt.scatter([sample_mean], [0.5], s=200, color='blue', zorder=5, label='Sample Mean')\n",
        "\n",
        "# Confidence interval\n",
        "plt.plot([ci_lower, ci_upper], [0.5, 0.5], 'b-', linewidth=3, label='95% CI')\n",
        "plt.plot([ci_lower, ci_lower], [0.45, 0.55], 'b-', linewidth=3)\n",
        "plt.plot([ci_upper, ci_upper], [0.45, 0.55], 'b-', linewidth=3)\n",
        "\n",
        "# Null hypothesis value\n",
        "plt.axvline(hypothesized_mean, color='red', linestyle='--', linewidth=2,\n",
        "            label=f'Hâ‚€: Î¼ = {hypothesized_mean}')\n",
        "\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel('Blood Pressure Reduction (points)')\n",
        "plt.title('95% Confidence Interval for Mean BP Reduction')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n95% Confidence Interval: [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
        "print(f\"\\nInterpretation:\")\n",
        "print(f\"We are 95% confident that the true mean BP reduction is between\")\n",
        "print(f\"{ci_lower:.2f} and {ci_upper:.2f} points.\")\n",
        "print(f\"\\nNote: The null hypothesis value ({hypothesized_mean}) is \", end=\"\")\n",
        "if hypothesized_mean < ci_lower or hypothesized_mean > ci_upper:\n",
        "    print(\"NOT in the interval.\")\n",
        "    print(\"This agrees with our decision to reject Hâ‚€!\")\n",
        "else:\n",
        "    print(\"in the interval.\")\n",
        "    print(\"This agrees with our decision to fail to reject Hâ‚€!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzqngoX3A7gL"
      },
      "source": [
        "### ðŸŽ¯ Your Turn: Complete Hypothesis Test\n",
        "\n",
        "**Scenario**: A coffee shop claims their espresso machine makes shots with an average of 30ml of espresso. You suspect it's actually less. You measure 50 shots and find:\n",
        "- Sample mean: 28.5 ml\n",
        "- Sample std: 3.2 ml\n",
        "\n",
        "Test at Î± = 0.05 significance level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Z5ml3UmA7gL"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# 1. State the hypotheses\n",
        "# Hâ‚€: Î¼ = 30  (claim is correct)\n",
        "# Hâ‚: Î¼ < 30  (espresso machine makes less)\n",
        "\n",
        "# 2. Set significance level\n",
        "alpha = ___  # Fill in\n",
        "\n",
        "# 3. Collect data (given)\n",
        "sample_mean = ___  # Fill in\n",
        "hypothesized_mean = ___  # Fill in\n",
        "sample_std = ___  # Fill in\n",
        "n = ___  # Fill in\n",
        "\n",
        "# 4. Calculate test statistic\n",
        "standard_error = sample_std / np.sqrt(n)\n",
        "z_statistic = (sample_mean - hypothesized_mean) / standard_error\n",
        "\n",
        "# 5. Find critical value (one-tailed, left tail)\n",
        "z_critical = norm.ppf(alpha)  # Left tail\n",
        "\n",
        "# 6. Calculate p-value\n",
        "p_value = norm.cdf(z_statistic)  # Left tail\n",
        "\n",
        "# 7. Make decision\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"HYPOTHESIS TEST: Espresso Machine\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Test Statistic: {z_statistic:.4f}\")\n",
        "print(f\"Critical Value: {z_critical:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"\\nDecision: \", end=\"\")\n",
        "if p_value < alpha:\n",
        "    print(\"Reject Hâ‚€\")\n",
        "    print(\"Conclusion: There is evidence that the machine makes less than 30ml.\")\n",
        "else:\n",
        "    print(\"Fail to reject Hâ‚€\")\n",
        "    print(\"Conclusion: Insufficient evidence that the machine makes less than 30ml.\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 8. Calculate 95% confidence interval\n",
        "z_ci = norm.ppf(0.975)  # Two-tailed\n",
        "margin = z_ci * standard_error\n",
        "ci_lower = sample_mean - margin\n",
        "ci_upper = sample_mean + margin\n",
        "print(f\"\\n95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8ELKq6UA7gL"
      },
      "source": [
        "---\n",
        "## Summary: The Journey from Probability to Inference\n",
        "\n",
        "Let's reflect on what we've learned and how it all connects:\n",
        "\n",
        "### The Building Blocks\n",
        "\n",
        "1. **Expected Value** â†’ Told us the \"center\" of distributions\n",
        "2. **Binomial Distribution** â†’ Modeled repeated yes/no experiments  \n",
        "3. **Normal Distribution** â†’ Emerged as the limit of the binomial\n",
        "4. **Least Squares & MLE** â†’ Gave us methods to estimate parameters\n",
        "5. **Conditional Probability** â†’ Showed us how to update beliefs with evidence\n",
        "6. **Distribution Functions** â†’ Provided tools to work with probabilities\n",
        "7. **Law of Large Numbers** â†’ Guaranteed stability with large samples\n",
        "8. **Central Limit Theorem** â†’ Enabled us to use normal theory for inference\n",
        "\n",
        "### The Culmination: Hypothesis Testing\n",
        "\n",
        "All these concepts come together in hypothesis testing:\n",
        "\n",
        "- We use **expected value** to define what we expect under Hâ‚€\n",
        "- We rely on the **Central Limit Theorem** to know the sampling distribution is normal\n",
        "- We use **standard error** (from CLT) to standardize our test statistic\n",
        "- We use **CDF** to find critical values and p-values\n",
        "- We use **confidence intervals** to provide a range estimate\n",
        "- We balance **Type I and Type II errors** based on the context\n",
        "\n",
        "### Why This Matters\n",
        "\n",
        "Hypothesis testing is the foundation of:\n",
        "- A/B testing in tech companies\n",
        "- Clinical trials in medicine  \n",
        "- Quality control in manufacturing\n",
        "- Policy evaluation in government\n",
        "- Scientific research across all fields\n",
        "\n",
        "You now have the statistical foundation to make data-driven decisions with confidence!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO8mTmSBA7gL"
      },
      "source": [
        "---\n",
        "## Final Practice Problem\n",
        "\n",
        "**Scenario**: You're a data scientist at a social media company. You've redesigned the user interface and want to know if it increases average daily time spent on the platform.\n",
        "\n",
        "- **Before redesign**: average = 45 minutes/day (population mean)\n",
        "- **After redesign** (n=200 users): mean = 47.5 minutes, std = 12 minutes\n",
        "\n",
        "Conduct a hypothesis test and interpret the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD4k9DJwA7gL"
      },
      "outputs": [],
      "source": [
        "# YOUR COMPLETE SOLUTION HERE\n",
        "# Remember to:\n",
        "# 1. State hypotheses\n",
        "# 2. Choose Î±\n",
        "# 3. Calculate test statistic\n",
        "# 4. Find critical value and p-value\n",
        "# 5. Make decision\n",
        "# 6. State conclusion\n",
        "# 7. Calculate confidence interval\n",
        "# 8. Visualize the test\n",
        "\n",
        "# Write your code below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmvRh97OA7gL"
      },
      "source": [
        "---\n",
        "## Congratulations! ðŸŽ‰\n",
        "\n",
        "You've completed a comprehensive journey through statistical inference!\n",
        "\n",
        "### What You've Mastered:\n",
        "\n",
        "âœ… How to quantify uncertainty with expected value  \n",
        "âœ… How discrete and continuous distributions work  \n",
        "âœ… How to estimate parameters from data  \n",
        "âœ… How to work with conditional probabilities  \n",
        "âœ… How to use different distribution functions  \n",
        "âœ… Why the Central Limit Theorem is so powerful  \n",
        "âœ… How to conduct hypothesis tests with confidence  \n",
        "âœ… How to interpret p-values and confidence intervals  \n",
        "âœ… How to balance Type I and Type II errors  \n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "- Practice with real datasets\n",
        "- Learn about t-tests, chi-square tests, ANOVA\n",
        "- Explore Bayesian statistics\n",
        "- Apply these concepts to your own data science projects\n",
        "\n",
        "Remember: Statistics is not just about formulasâ€”it's about thinking clearly about uncertainty and making principled decisions in the face of incomplete information.\n",
        "\n",
        "**Keep exploring, keep questioning, and keep learning!** ðŸ“ŠðŸ”¬ðŸŽ“"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}