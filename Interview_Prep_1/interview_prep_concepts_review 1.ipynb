{"cells":[{"cell_type":"markdown","metadata":{"id":"E33jqw_GFVT0"},"source":["# Data Science Interview Preparation: Concepts & Code Review\n","\n","This notebook provides a comprehensive review of key data modeling, database, and data science concepts commonly encountered in technical interviews. Each section includes terminology definitions, conceptual explanations, and Python code examples.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"vRN546TKFVT1"},"source":["## 1. Database Fundamentals\n","\n","### Key Terminology\n","\n","- **Database**: An organized collection of structured data stored electronically\n","- **DBMS (Database Management System)**: Software that manages database access and operations\n","- **RDBMS (Relational Database Management System)**: Database system based on the relational model (e.g., PostgreSQL, MySQL)\n","- **Schema**: The structure/organization of a database including tables, columns, and relationships\n","- **Table**: A collection of related data organized in rows and columns\n","- **Primary Key**: Unique identifier for each row in a table\n","- **Foreign Key**: A column that references the primary key of another table\n","- **Index**: Data structure that improves query performance\n","- **Normalization**: Process of organizing data to reduce redundancy\n","- **ACID Properties**: Atomicity, Consistency, Isolation, Durability - guarantees for database transactions\n","\n","### Connecting to Databases in Python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uBy5w-4LFVT2"},"outputs":[],"source":["# Install required packages (run once)\n","# !pip install pandas sqlalchemy psycopg2-binary sqlite3\n","\n","import pandas as pd\n","import sqlite3\n","from sqlalchemy import create_engine\n","\n","# Example 1: SQLite connection (lightweight, file-based)\n","conn = sqlite3.connect('example.db')\n","\n","# Example 2: PostgreSQL connection (production databases)\n","# engine = create_engine('postgresql://user:password@localhost:5432/database_name')\n","\n","print(\"Database connections established\")"]},{"cell_type":"markdown","metadata":{"id":"RbcbkVlEFVT2"},"source":["---\n","## 2. SQL - Structured Query Language\n","\n","### SQL Categories\n","\n","1. **DDL (Data Definition Language)**: Defines database structure\n","   - `CREATE`, `ALTER`, `DROP`, `TRUNCATE`\n","\n","2. **DML (Data Manipulation Language)**: Manipulates data\n","   - `INSERT`, `UPDATE`, `DELETE`\n","\n","3. **DQL (Data Query Language)**: Queries data\n","   - `SELECT`\n","\n","4. **DCL (Data Control Language)**: Controls access\n","   - `GRANT`, `REVOKE`\n","\n","5. **TCL (Transaction Control Language)**: Manages transactions\n","   - `COMMIT`, `ROLLBACK`, `SAVEPOINT`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1Cthdt2FVT3"},"outputs":[],"source":["# DDL Example: Creating tables\n","cursor = conn.cursor()\n","\n","# Create a customers table\n","cursor.execute('''\n","CREATE TABLE IF NOT EXISTS customers (\n","    customer_id INTEGER PRIMARY KEY AUTOINCREMENT,\n","    first_name TEXT NOT NULL,\n","    last_name TEXT NOT NULL,\n","    email TEXT UNIQUE,\n","    created_date DATE DEFAULT CURRENT_DATE\n",")\n","''')\n","\n","# Create an orders table with foreign key\n","cursor.execute('''\n","CREATE TABLE IF NOT EXISTS orders (\n","    order_id INTEGER PRIMARY KEY AUTOINCREMENT,\n","    customer_id INTEGER,\n","    order_date DATE,\n","    total_amount DECIMAL(10, 2),\n","    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",")\n","''')\n","\n","conn.commit()\n","print(\"Tables created successfully\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCjIEEHnFVT3"},"outputs":[],"source":["# DML Example: Inserting and updating data\n","\n","# INSERT\n","cursor.execute('''\n","INSERT INTO customers (first_name, last_name, email)\n","VALUES (?, ?, ?)\n","''', ('John', 'Doe', 'john.doe@email.com'))\n","\n","cursor.execute('''\n","INSERT INTO customers (first_name, last_name, email)\n","VALUES (?, ?, ?)\n","''', ('Jane', 'Smith', 'jane.smith@email.com'))\n","\n","# INSERT multiple orders\n","orders_data = [\n","    (1, '2024-01-15', 150.00),\n","    (1, '2024-02-20', 275.50),\n","    (2, '2024-01-18', 99.99)\n","]\n","\n","cursor.executemany('''\n","INSERT INTO orders (customer_id, order_date, total_amount)\n","VALUES (?, ?, ?)\n","''', orders_data)\n","\n","# UPDATE\n","cursor.execute('''\n","UPDATE customers\n","SET email = ?\n","WHERE customer_id = ?\n","''', ('john.updated@email.com', 1))\n","\n","conn.commit()\n","print(\"Data inserted and updated successfully\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p88JisbJFVT3"},"outputs":[],"source":["# DQL Example: Querying data with SELECT\n","\n","# Basic SELECT\n","df = pd.read_sql_query('SELECT * FROM customers', conn)\n","print(\"All Customers:\")\n","print(df)\n","print()\n","\n","# SELECT with JOIN\n","query = '''\n","SELECT\n","    c.first_name,\n","    c.last_name,\n","    o.order_date,\n","    o.total_amount\n","FROM customers c\n","INNER JOIN orders o ON c.customer_id = o.customer_id\n","ORDER BY o.order_date\n","'''\n","\n","df_orders = pd.read_sql_query(query, conn)\n","print(\"Customer Orders:\")\n","print(df_orders)\n","print()\n","\n","# Aggregation query\n","agg_query = '''\n","SELECT\n","    c.customer_id,\n","    c.first_name || ' ' || c.last_name as customer_name,\n","    COUNT(o.order_id) as total_orders,\n","    SUM(o.total_amount) as total_spent,\n","    AVG(o.total_amount) as avg_order_value\n","FROM customers c\n","LEFT JOIN orders o ON c.customer_id = o.customer_id\n","GROUP BY c.customer_id, customer_name\n","HAVING COUNT(o.order_id) > 0\n","'''\n","\n","df_agg = pd.read_sql_query(agg_query, conn)\n","print(\"Customer Summary:\")\n","print(df_agg)"]},{"cell_type":"markdown","metadata":{"id":"yCQStK6CFVT4"},"source":["### Common SQL Interview Queries\n","\n","**Window Functions** - Used for ranking, running totals, moving averages\n","\n","```sql\n","SELECT\n","    customer_id,\n","    order_date,\n","    total_amount,\n","    ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date) as order_number,\n","    SUM(total_amount) OVER (PARTITION BY customer_id ORDER BY order_date) as running_total\n","FROM orders;\n","```\n","\n","**Subqueries** - Query within a query\n","\n","```sql\n","SELECT *\n","FROM customers\n","WHERE customer_id IN (\n","    SELECT customer_id\n","    FROM orders\n","    WHERE total_amount > 200\n",");\n","```\n","\n","**CTEs (Common Table Expressions)** - Temporary named result sets\n","\n","```sql\n","WITH high_value_customers AS (\n","    SELECT customer_id, SUM(total_amount) as total\n","    FROM orders\n","    GROUP BY customer_id\n","    HAVING SUM(total_amount) > 500\n",")\n","SELECT c.*, hvc.total\n","FROM customers c\n","JOIN high_value_customers hvc ON c.customer_id = hvc.customer_id;\n","```"]},{"cell_type":"markdown","metadata":{"id":"-kHLCywxFVT4"},"source":["---\n","## 3. Data Modeling Concepts\n","\n","### Entity-Relationship Diagrams (ERD)\n","\n","**Key Components:**\n","- **Entity**: Object or concept (represented as rectangles)\n","- **Attribute**: Property of an entity (represented as ovals)\n","- **Relationship**: Association between entities (represented as diamonds)\n","\n","**Cardinality Types:**\n","- **One-to-One (1:1)**: Each entity in A relates to one entity in B\n","- **One-to-Many (1:N)**: Each entity in A can relate to many in B\n","- **Many-to-Many (M:N)**: Entities in A can relate to many in B and vice versa\n","\n","### Normalization\n","\n","**Purpose**: Organize data to reduce redundancy and improve data integrity\n","\n","**Normal Forms:**\n","\n","1. **First Normal Form (1NF)**:\n","   - Each column contains atomic (indivisible) values\n","   - Each column contains values of a single type\n","   - Each column has a unique name\n","   - Order doesn't matter\n","\n","2. **Second Normal Form (2NF)**:\n","   - Must be in 1NF\n","   - All non-key attributes are fully dependent on the primary key\n","   - No partial dependencies\n","\n","3. **Third Normal Form (3NF)**:\n","   - Must be in 2NF\n","   - No transitive dependencies (non-key attributes don't depend on other non-key attributes)\n","\n","4. **Boyce-Codd Normal Form (BCNF)**:\n","   - Must be in 3NF\n","   - Every determinant is a candidate key"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EF-HwUThFVT5"},"outputs":[],"source":["# Example: Unnormalized vs Normalized data\n","\n","# Unnormalized (violates 1NF - multiple values in phone_numbers)\n","unnormalized_data = pd.DataFrame({\n","    'employee_id': [1, 2],\n","    'name': ['Alice Johnson', 'Bob Smith'],\n","    'department': ['Engineering', 'Marketing'],\n","    'phone_numbers': ['555-1234, 555-5678', '555-9999']\n","})\n","\n","print(\"Unnormalized Table (Violates 1NF):\")\n","print(unnormalized_data)\n","print()\n","\n","# Normalized (1NF compliant)\n","employees = pd.DataFrame({\n","    'employee_id': [1, 2],\n","    'name': ['Alice Johnson', 'Bob Smith'],\n","    'department_id': [1, 2]\n","})\n","\n","phone_numbers = pd.DataFrame({\n","    'phone_id': [1, 2, 3],\n","    'employee_id': [1, 1, 2],\n","    'phone_number': ['555-1234', '555-5678', '555-9999']\n","})\n","\n","departments = pd.DataFrame({\n","    'department_id': [1, 2],\n","    'department_name': ['Engineering', 'Marketing']\n","})\n","\n","print(\"Normalized Tables (1NF, 2NF, 3NF):\")\n","print(\"\\nEmployees:\")\n","print(employees)\n","print(\"\\nPhone Numbers:\")\n","print(phone_numbers)\n","print(\"\\nDepartments:\")\n","print(departments)"]},{"cell_type":"markdown","metadata":{"id":"ZcGWrqboFVT5"},"source":["---\n","## 4. Python Data Manipulation\n","\n","### Pandas - Essential Operations\n","\n","**Key Terminology:**\n","- **DataFrame**: 2D labeled data structure (like a table)\n","- **Series**: 1D labeled array\n","- **Index**: Row labels\n","- **Columns**: Column labels\n","- **Vectorization**: Operations on entire arrays without explicit loops"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsBUcZSmFVT5"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","# Creating sample data\n","data = {\n","    'product_id': [101, 102, 103, 104, 105],\n","    'product_name': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones'],\n","    'category': ['Electronics', 'Accessories', 'Accessories', 'Electronics', 'Accessories'],\n","    'price': [999.99, 25.50, 75.00, 299.99, 89.99],\n","    'quantity_sold': [50, 200, 150, 75, 120]\n","}\n","\n","df = pd.DataFrame(data)\n","print(\"Original DataFrame:\")\n","print(df)\n","print(f\"\\nShape: {df.shape}\")\n","print(f\"\\nData Types:\\n{df.dtypes}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikmEcSsCFVT5"},"outputs":[],"source":["# Common DataFrame operations\n","\n","# 1. Filtering\n","print(\"Products over $50:\")\n","print(df[df['price'] > 50])\n","print()\n","\n","# 2. Sorting\n","print(\"Sorted by price (descending):\")\n","print(df.sort_values('price', ascending=False))\n","print()\n","\n","# 3. Grouping and Aggregation\n","print(\"Summary by category:\")\n","summary = df.groupby('category').agg({\n","    'price': ['mean', 'min', 'max'],\n","    'quantity_sold': 'sum'\n","})\n","print(summary)\n","print()\n","\n","# 4. Creating new columns\n","df['revenue'] = df['price'] * df['quantity_sold']\n","print(\"DataFrame with revenue column:\")\n","print(df[['product_name', 'price', 'quantity_sold', 'revenue']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIhkYXO4FVT6"},"outputs":[],"source":["# Handling missing data\n","df_with_nulls = df.copy()\n","df_with_nulls.loc[1, 'price'] = np.nan\n","df_with_nulls.loc[3, 'quantity_sold'] = np.nan\n","\n","print(\"DataFrame with missing values:\")\n","print(df_with_nulls)\n","print(f\"\\nMissing values per column:\\n{df_with_nulls.isnull().sum()}\")\n","print()\n","\n","# Methods to handle missing data\n","print(\"Fill with mean:\")\n","df_filled = df_with_nulls.fillna(df_with_nulls.mean(numeric_only=True))\n","print(df_filled)\n","print()\n","\n","print(\"Drop rows with any null:\")\n","df_dropped = df_with_nulls.dropna()\n","print(df_dropped)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aMuaBhtKFVT6"},"outputs":[],"source":["# Merging DataFrames (SQL-like joins)\n","\n","# Create additional data\n","suppliers = pd.DataFrame({\n","    'product_id': [101, 102, 103, 106],\n","    'supplier_name': ['TechCorp', 'AccessoriesPlus', 'KeyboardKing', 'DisplayPro']\n","})\n","\n","print(\"Original products DataFrame:\")\n","print(df[['product_id', 'product_name']])\n","print(\"\\nSuppliers DataFrame:\")\n","print(suppliers)\n","print()\n","\n","# Inner join\n","print(\"Inner Join:\")\n","inner = pd.merge(df, suppliers, on='product_id', how='inner')\n","print(inner[['product_id', 'product_name', 'supplier_name']])\n","print()\n","\n","# Left join\n","print(\"Left Join (keep all products):\")\n","left = pd.merge(df, suppliers, on='product_id', how='left')\n","print(left[['product_id', 'product_name', 'supplier_name']])"]},{"cell_type":"markdown","metadata":{"id":"SmkDw460FVT6"},"source":["---\n","## 5. Database Design Life Cycle\n","\n","### Phases\n","\n","1. **Requirements Analysis**: Gather and document business requirements\n","2. **Conceptual Design**: Create ERD showing entities and relationships\n","3. **Logical Design**: Convert ERD to normalized relational schema\n","4. **Physical Design**: Define storage structures, indexes, partitions\n","5. **Implementation**: Create database, tables, and load data\n","6. **Testing & Deployment**: Validate and deploy to production\n","7. **Maintenance**: Monitor, optimize, and update as needed\n","\n","### Database Types Comparison\n","\n","| Feature | RDBMS | NoSQL | Graph DB | Vector Store |\n","|---------|-------|-------|----------|-------------|\n","| **Structure** | Tables/Rows | Documents/Collections | Nodes/Edges | Embeddings/Vectors |\n","| **Schema** | Fixed | Flexible | Flexible | Flexible |\n","| **Relationships** | Foreign Keys | Embedded/References | Native | Similarity |\n","| **Scaling** | Vertical | Horizontal | Horizontal | Horizontal |\n","| **Use Case** | Transactions | High-volume | Connections | Semantic Search |\n","| **Examples** | PostgreSQL, MySQL | MongoDB, Cassandra | Neo4j, Amazon Neptune | Pinecone, Weaviate |"]},{"cell_type":"markdown","metadata":{"id":"zAcSyNneFVT6"},"source":["---\n","## 6. Data Warehousing Concepts\n","\n","### Key Terminology\n","\n","- **Data Warehouse**: Centralized repository for integrated data from multiple sources\n","- **ETL (Extract, Transform, Load)**: Process of moving data from sources to warehouse\n","- **OLTP (Online Transaction Processing)**: Day-to-day transactional systems\n","- **OLAP (Online Analytical Processing)**: Systems optimized for complex queries and analysis\n","- **Fact Table**: Contains measurable, quantitative data (sales, revenue)\n","- **Dimension Table**: Contains descriptive attributes (customer info, product details)\n","- **Star Schema**: Fact table surrounded by dimension tables\n","- **Snowflake Schema**: Normalized version of star schema\n","- **Data Mart**: Subset of data warehouse focused on specific business area\n","- **Data Lake**: Storage repository for raw, unstructured data\n","\n","### Star Schema Example"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16fs91IzFVT6"},"outputs":[],"source":["# Creating a simple star schema example\n","\n","# Fact table - Sales\n","fact_sales = pd.DataFrame({\n","    'sale_id': [1, 2, 3, 4],\n","    'date_key': [20240101, 20240102, 20240102, 20240103],\n","    'product_key': [1, 2, 1, 3],\n","    'customer_key': [101, 102, 101, 103],\n","    'quantity': [2, 1, 3, 1],\n","    'unit_price': [100.00, 50.00, 100.00, 75.00],\n","    'total_amount': [200.00, 50.00, 300.00, 75.00]\n","})\n","\n","# Dimension table - Products\n","dim_products = pd.DataFrame({\n","    'product_key': [1, 2, 3],\n","    'product_name': ['Widget A', 'Widget B', 'Widget C'],\n","    'category': ['Electronics', 'Home', 'Electronics']\n","})\n","\n","# Dimension table - Customers\n","dim_customers = pd.DataFrame({\n","    'customer_key': [101, 102, 103],\n","    'customer_name': ['Acme Corp', 'Tech Solutions', 'Global Industries'],\n","    'region': ['West', 'East', 'Central']\n","})\n","\n","# Dimension table - Date\n","dim_date = pd.DataFrame({\n","    'date_key': [20240101, 20240102, 20240103],\n","    'date': ['2024-01-01', '2024-01-02', '2024-01-03'],\n","    'month': [1, 1, 1],\n","    'quarter': [1, 1, 1],\n","    'year': [2024, 2024, 2024]\n","})\n","\n","print(\"Star Schema Structure:\")\n","print(\"\\nFact Table (Sales):\")\n","print(fact_sales)\n","print(\"\\nDimension - Products:\")\n","print(dim_products)\n","print(\"\\nDimension - Customers:\")\n","print(dim_customers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m8zE98SNFVT6"},"outputs":[],"source":["# Analytical query on star schema\n","analysis = fact_sales.merge(dim_products, on='product_key') \\\n","                     .merge(dim_customers, on='customer_key') \\\n","                     .merge(dim_date, on='date_key')\n","\n","# Summary by region\n","regional_summary = analysis.groupby('region').agg({\n","    'total_amount': 'sum',\n","    'quantity': 'sum',\n","    'sale_id': 'count'\n","}).rename(columns={'sale_id': 'num_transactions'})\n","\n","print(\"Sales Summary by Region:\")\n","print(regional_summary)"]},{"cell_type":"markdown","metadata":{"id":"u-_eadsRFVT7"},"source":["---\n","## 7. API Concepts\n","\n","### REST API Principles\n","\n","**REST (Representational State Transfer)** - Architectural style for web services\n","\n","**HTTP Methods:**\n","- **GET**: Retrieve data (read-only)\n","- **POST**: Create new resource\n","- **PUT**: Update entire resource\n","- **PATCH**: Partial update of resource\n","- **DELETE**: Remove resource\n","\n","**Status Codes:**\n","- **2xx**: Success (200 OK, 201 Created)\n","- **3xx**: Redirection\n","- **4xx**: Client errors (400 Bad Request, 404 Not Found)\n","- **5xx**: Server errors (500 Internal Server Error)\n","\n","### FastAPI Example"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrdnZvB1FVT7"},"outputs":[],"source":["# Basic FastAPI structure (for reference - won't run in notebook)\n","\"\"\"\n","from fastapi import FastAPI, HTTPException\n","from pydantic import BaseModel\n","\n","app = FastAPI()\n","\n","class Product(BaseModel):\n","    id: int\n","    name: str\n","    price: float\n","\n","# In-memory database\n","products_db = {}\n","\n","@app.get(\"/\")\n","def read_root():\n","    return {\"message\": \"Welcome to Products API\"}\n","\n","@app.get(\"/products/{product_id}\")\n","def read_product(product_id: int):\n","    if product_id not in products_db:\n","        raise HTTPException(status_code=404, detail=\"Product not found\")\n","    return products_db[product_id]\n","\n","@app.post(\"/products/\")\n","def create_product(product: Product):\n","    if product.id in products_db:\n","        raise HTTPException(status_code=400, detail=\"Product already exists\")\n","    products_db[product.id] = product\n","    return product\n","\n","@app.put(\"/products/{product_id}\")\n","def update_product(product_id: int, product: Product):\n","    if product_id not in products_db:\n","        raise HTTPException(status_code=404, detail=\"Product not found\")\n","    products_db[product_id] = product\n","    return product\n","\n","@app.delete(\"/products/{product_id}\")\n","def delete_product(product_id: int):\n","    if product_id not in products_db:\n","        raise HTTPException(status_code=404, detail=\"Product not found\")\n","    del products_db[product_id]\n","    return {\"message\": \"Product deleted\"}\n","\"\"\"\n","\n","print(\"FastAPI code structure shown above (reference only)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bXpVWUpvFVT7"},"outputs":[],"source":["# Working with APIs using requests library\n","import requests\n","\n","# Example: Public API call\n","# (This is a real endpoint you can test)\n","try:\n","    response = requests.get('https://api.github.com/users/github')\n","\n","    print(f\"Status Code: {response.status_code}\")\n","    print(f\"Response Headers: {dict(list(response.headers.items())[:3])}\")\n","\n","    if response.status_code == 200:\n","        data = response.json()\n","        print(f\"\\nUser: {data.get('login')}\")\n","        print(f\"Name: {data.get('name')}\")\n","        print(f\"Public Repos: {data.get('public_repos')}\")\n","except Exception as e:\n","    print(f\"API call failed: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"WgKH7V3HFVT7"},"source":["---\n","## 8. Interview Preparation Tips\n","\n","### Common Technical Interview Topics\n","\n","1. **SQL Queries**:\n","   - Know JOINs (INNER, LEFT, RIGHT, FULL)\n","   - Window functions (ROW_NUMBER, RANK, LAG/LEAD)\n","   - Aggregations with GROUP BY and HAVING\n","   - Subqueries and CTEs\n","\n","2. **Data Modeling**:\n","   - ERD creation and interpretation\n","   - Normalization and when to denormalize\n","   - Primary vs. foreign keys\n","   - Cardinality relationships\n","\n","3. **Python/Pandas**:\n","   - DataFrame manipulation\n","   - Merging and joining data\n","   - Handling missing values\n","   - GroupBy operations\n","\n","4. **Database Concepts**:\n","   - ACID properties\n","   - Indexes and performance\n","   - Transactions\n","   - Database types (RDBMS vs NoSQL)\n","\n","5. **System Design**:\n","   - Star vs. snowflake schema\n","   - ETL processes\n","   - Data warehouse architecture\n","   - Scalability considerations\n","\n","### Practice Questions to Consider\n","\n","1. \"Write a SQL query to find the second highest salary\"\n","2. \"Design a database schema for an e-commerce platform\"\n","3. \"How would you handle missing data in a dataset?\"\n","4. \"Explain the difference between DELETE, TRUNCATE, and DROP\"\n","5. \"When would you use a NoSQL database over a relational database?\"\n","6. \"How would you optimize a slow-running query?\"\n","7. \"Design an ETL pipeline for a data warehouse\"\n","8. \"What are database indexes and when should you use them?\""]},{"cell_type":"markdown","metadata":{"id":"_4y1hez1FVT7"},"source":["---\n","## Summary Checklist\n","\n","Before your interview, ensure you can:\n","\n","✓ Write basic to intermediate SQL queries (SELECT, JOIN, GROUP BY, window functions)  \n","✓ Explain database normalization and the different normal forms  \n","✓ Create and interpret ERD diagrams  \n","✓ Manipulate data using pandas (filtering, grouping, merging)  \n","✓ Explain ACID properties and transactions  \n","✓ Describe the difference between OLTP and OLAP systems  \n","✓ Understand star schema vs. snowflake schema  \n","✓ Explain REST API principles and HTTP methods  \n","✓ Connect to databases using Python  \n","✓ Discuss trade-offs between different database types  \n","\n","---\n","\n","**Good luck with your interview preparation!**"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}
